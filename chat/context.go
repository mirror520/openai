package chat

import (
	"encoding/json"

	"github.com/oklog/ulid/v2"
)

type ChatID ulid.ULID

func (id ChatID) String() string {
	return ulid.ULID(id).String()
}

type Context struct {
	ID       ChatID
	Model    string
	Messages []*Message
	*Options
}

func NewContext(model string, raw json.RawMessage) (*Context, error) {
	ctx := new(Context)
	ctx.ID = ChatID(ulid.Make())
	ctx.Model = model
	ctx.Messages = make([]*Message, 0)

	var opts *Options
	err := json.Unmarshal(raw, &opts)
	if err != nil {
		return nil, err
	}

	ctx.Options = opts

	return ctx, nil
}

func (ctx *Context) AddMessage(msg *Message) {
	ctx.Messages = append(ctx.Messages, msg)
}

func (ctx *Context) Request() *Request {
	return &Request{
		Model:    ctx.Model,
		Messages: ctx.Messages,
		Options:  *ctx.Options, // clone
	}
}

type Options struct {

	// What sampling temperature to use, between 0 and 2.
	// Higher values like 0.8 will make the output more random,
	// while lower values like 0.2 will make it more focused and deterministic.
	//
	// We generally recommend altering this or top_p but not both.
	Temperature *float64 `json:"temperature,omitempty"`

	// An alternative to sampling with temperature, called nucleus sampling,
	// where the model considers the results of the tokens with top_p probability mass.
	// So 0.1 means only the tokens comprising the top 10% probability mass are considered.
	//
	// We generally recommend altering this or temperature but not both.
	TopP *float64 `json:"top_p,omitempty"`

	// How many chat completion choices to generate for each input message.
	N *int `json:"n,omitempty"`

	// If set, partial message deltas will be sent, like in ChatGPT.
	// Tokens will be sent as data-only server-sent events as they become available,
	// with the stream terminated by a data: [DONE] message
	Stream *bool `json:"stream,omitempty"`

	// Up to 4 sequences where the API will stop generating further tokens.
	Stop []string `json:"stop,omitempty"`

	// The maximum number of tokens to generate in the chat completion.
	//
	// The total length of input tokens and generated tokens is limited by the model's context length.
	MaxTokens *int `json:"max_tokens,omitempty"`

	// Number between -2.0 and 2.0.
	// Positive values penalize new tokens based on whether they appear in the text so far,
	// increasing the model's likelihood to talk about new topics.
	PresencePenalty *float64 `json:"presence_penalty,omitempty"`

	// Number between -2.0 and 2.0.
	// Positive values penalize new tokens based on their existing frequency in the text so far,
	// decreasing the model's likelihood to repeat the same line verbatim.
	FrequencyPenalty *float64 `json:"frequency_penalty,omitempty"`

	// Modify the likelihood of specified tokens appearing in the completion.
	//
	// Accepts a json object that maps tokens (specified by their token ID in the tokenizer)
	// to an associated bias value from -100 to 100. Mathematically,
	// the bias is added to the logits generated by the model prior to sampling.
	// The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection;
	// values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
	LogitBias map[string]int `json:"logit_bias,omitempty"`

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
	User *string `json:"user,omitempty"`
}

func (opts *Options) Update(raw json.RawMessage) error {
	var newOpts *Options
	if err := json.Unmarshal(raw, &newOpts); err != nil {
		return err
	}

	if newOpts.Temperature != nil {
		opts.Temperature = newOpts.Temperature
	}

	if newOpts.TopP != nil {
		opts.TopP = newOpts.TopP
	}

	if newOpts.N != nil {
		opts.N = newOpts.N
	}

	if newOpts.Stream != nil {
		opts.Stream = newOpts.Stream
	}

	if newOpts.Stop != nil {
		opts.Stop = newOpts.Stop
	}

	if newOpts.MaxTokens != nil {
		opts.MaxTokens = newOpts.MaxTokens
	}

	if newOpts.PresencePenalty != nil {
		opts.PresencePenalty = newOpts.PresencePenalty
	}

	if newOpts.FrequencyPenalty != nil {
		opts.FrequencyPenalty = newOpts.FrequencyPenalty
	}

	if newOpts.LogitBias != nil {
		opts.LogitBias = newOpts.LogitBias
	}

	if newOpts.User != nil {
		opts.User = newOpts.User
	}

	return nil
}
